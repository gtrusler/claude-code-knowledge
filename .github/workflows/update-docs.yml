name: Update Claude Code Docs

on:
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - '.github/workflows/update-docs.yml'

jobs:
  update-docs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 markdownify
    
    - name: Scrape documentation
      run: |
        cat > scraper.py << 'EOF'
        import requests
        from bs4 import BeautifulSoup
        import markdownify
        from datetime import datetime
        
        def scrape_claude_docs():
            base_url = "https://docs.anthropic.com/en/docs/claude-code"
            
            try:
                response = requests.get(base_url, timeout=30, headers={
                    'User-Agent': 'Mozilla/5.0 (compatible; Claude-Code-Docs-Scraper/1.0)'
                })
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Try multiple selectors
                content = None
                for selector in ['main', 'article', '[role="main"]', '.docs-content', '#content']:
                    content = soup.select_one(selector)
                    if content:
                        break
                
                if not content:
                    # Fallback: look for the largest div with text
                    divs = soup.find_all('div')
                    if divs:
                        content = max(divs, key=lambda d: len(d.get_text(strip=True)))
                
                if not content:
                    return f"# Claude Code Official Documentation\n\n*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}*\n\nUnable to scrape content - page structure may have changed."
                
                # Convert to markdown
                markdown = markdownify.markdownify(str(content), heading_style="ATX", strip=['script', 'style'])
                
                # Add header
                header = f"""# Claude Code Official Documentation

        *Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}*
        *Source: {base_url}*

        ---

        """
                return header + markdown
                
            except Exception as e:
                return f"# Claude Code Official Documentation\n\n*Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}*\n\nError: {str(e)}"
        
        if __name__ == "__main__":
            docs_content = scrape_claude_docs()
            
            with open('official/docs.md', 'w', encoding='utf-8') as f:
                f.write(docs_content)
            
            print("Documentation updated")
        EOF
        
        python scraper.py
    
    - name: Check for changes
      id: check
      run: |
        if git diff --quiet official/docs.md; then
          echo "No changes detected"
          echo "has_changes=false" >> $GITHUB_OUTPUT
        else
          echo "Changes detected"
          echo "has_changes=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push changes
      if: steps.check.outputs.has_changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add official/docs.md
        git commit -m "Update Claude Code documentation - $(date +'%Y-%m-%d')"
        git push
